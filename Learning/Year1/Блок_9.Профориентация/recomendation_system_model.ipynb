{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <center> Разбор кейса ML-инженера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf52Pxm2hiom"
      },
      "source": [
        "## Обучим и протестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgni61ptDR7",
        "outputId": "4d9d62cf-6edf-4003-895e-3c833a2b5518"
      },
      "outputs": [],
      "source": [
        "#!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3C_SMz6hiot"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sparse\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "qfCOflZnhiou",
        "outputId": "aa55bacd-ccab-45c0-e483-ef59d2698d94"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('data/ratings.csv')\n",
        "books = pd.read_csv('data/books.csv')\n",
        "tags = pd.read_csv('data/tags.csv')\n",
        "book_tags = pd.read_csv('data/book_tags.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1TBykVuhiov"
      },
      "outputs": [],
      "source": [
        "books.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVIwztA5hiov"
      },
      "outputs": [],
      "source": [
        "mapper = dict(zip(books.goodreads_book_id,books.book_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxVDaPkKhiow"
      },
      "outputs": [],
      "source": [
        "tags = pd.read_csv('data/tags_cleaned.csv')\n",
        "book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]\n",
        "book_tags['id'] = book_tags.goodreads_book_id.apply(lambda x: mapper[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd_WvCLDhiow"
      },
      "outputs": [],
      "source": [
        "book_tags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3piw5iXUhiox"
      },
      "outputs": [],
      "source": [
        "ratings_coo = sparse.coo_matrix((ratings.rating,(ratings.user_id, ratings.book_id)))\n",
        "feature_ratings  = sparse.coo_matrix(([1]*len(book_tags), (book_tags.id, book_tags.tag_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp7ydLG-hiox"
      },
      "source": [
        "Объявим вспомогательные константы для обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3bS12rOhioy"
      },
      "outputs": [],
      "source": [
        "#число потоков нашего процессора. Ставим 1, так как lightfm на macos ставится без OpenMP\n",
        "NUM_THREADS = 1\n",
        "\n",
        "#число параметров вектора \n",
        "NUM_COMPONENTS = 60\n",
        "\n",
        "#число эпох обучения\n",
        "NUM_EPOCHS = 10 \n",
        "\n",
        "#зерно датчика случайных чисел\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-1_C-UZhioy"
      },
      "source": [
        "На этапе создания модели мы используем библиотеку LightFM, чтобы сделать матричное разложение (ALS) наших рейтингов книг и получить два набора векторов. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGxL87INhioz"
      },
      "outputs": [],
      "source": [
        "#Разбиваем наш датасет на обучающую и тестовую выборки\n",
        "train, test = random_train_test_split(ratings_coo, test_percentage=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "#Создаём модель\n",
        "model = LightFM(\n",
        "    learning_rate=0.05, #темп (скорость) обучения\n",
        "    loss='warp', #loss-функция\n",
        "    no_components=NUM_COMPONENTS,#размерность вектора признаков\n",
        "    random_state=RANDON_STATE #генератор случайных чисел\n",
        ")\n",
        "\n",
        "#Обучаем модель\n",
        "model = model.fit(\n",
        "    train, #обучающая выборка\n",
        "    epochs=NUM_EPOCHS, #количество эпох обучения\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    item_features=feature_ratings #признаки товаров (рейтинги книг)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMupb7Schio0"
      },
      "source": [
        "Протестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U1waVUshio0"
      },
      "outputs": [],
      "source": [
        "#Тестируем нашу модель\n",
        "precision_score = precision_at_k(\n",
        "    model, #модель\n",
        "    test, #тестовая выборка\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    k=10, #количество предложений\n",
        "    item_features=feature_ratings #признаки товаров\n",
        ").mean() #усредняем результаты\n",
        " \n",
        "recall_score = recall_at_k(\n",
        "    model, #модель\n",
        "    test, #тестовая выборка\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    k=10, #количество предложений\n",
        "    item_features=feature_ratings #признаки товаров\n",
        ").mean() #усредняем результаты\n",
        "\n",
        "print(recall_score, precision_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUskAXXhio1"
      },
      "source": [
        "Сохраним модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_uaCAe6hio1"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30o9Rtgyhio2"
      },
      "source": [
        "## Добавим эмбеддинги к модели и посмотрим, что получилось"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqsUKn57hio2"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQyl1ymbhio2"
      },
      "outputs": [],
      "source": [
        "# Достаём эбмеддинги\n",
        "item_biases, item_embeddings = model.get_item_representations(features=feature_ratings)\n",
        "\n",
        "print(item_biases.shape, item_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install nmslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi1DHdBKhio3"
      },
      "outputs": [],
      "source": [
        "import nmslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NscQUR47hio3"
      },
      "outputs": [],
      "source": [
        "#Инициализируем наш граф для поиска\n",
        "nms_idx = nmslib.init(method='hnsw', space='cosinesimil')\n",
        " \n",
        "#Начинаем добавлять наши книги в граф\n",
        "nms_idx.addDataPointBatch(item_embeddings)\n",
        "nms_idx.createIndex(print_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCtnO4s9hio3"
      },
      "outputs": [],
      "source": [
        "#Вспомогательная функция для поиска по графу\n",
        "def nearest_books_nms(book_id, index, n=10):\n",
        "    nn = index.knnQuery(item_embeddings[book_id], k=n)\n",
        "    return nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PMM_uHfhio4"
      },
      "source": [
        "Найдем id книги 1984"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da3eHj7chio5"
      },
      "outputs": [],
      "source": [
        "#Отфильтруем только те, где в названии встречается подстрока \"1984\"\n",
        "books[books['title'].apply(lambda x: x.lower().find('1984')) >= 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hxEWTJghio5"
      },
      "source": [
        "Теперь найдем все похожие книги и посмотрим на них"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Вызываем функцию для поиска ближайших соседей\n",
        "print(nearest_books_nms(846, nms_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaVVOV9Whio6"
      },
      "outputs": [],
      "source": [
        "#Выделяем идентификаторы рекомендованных книг\n",
        "nbm = nearest_books_nms(846, nms_idx)[0]\n",
        "nbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTred3b8hio6"
      },
      "outputs": [],
      "source": [
        "#Посмотрим на авторов и названия рекомендованных книг\n",
        "books[books.book_id.isin(nbm)][['authors', 'title']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV45_3xhhio7"
      },
      "source": [
        "Сохраним эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUk-Xx4Zhio7"
      },
      "outputs": [],
      "source": [
        "with open('item_embeddings.pkl', 'wb') as file:\n",
        "    pickle.dump(item_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.15 ('rec_sys')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "4e4104bd57aa2b23b5ece499e6a495477546c5bc7859abce1e85f57e6cf8bee2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
=======
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Разбор кейса ML-инженера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf52Pxm2hiom"
   },
   "source": [
    "## Обучим и протестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEgni61ptDR7",
    "outputId": "4d9d62cf-6edf-4003-895e-3c833a2b5518"
   },
   "outputs": [],
   "source": [
    "#!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\anzel\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (75.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nmslib\n",
      "  Using cached nmslib-2.1.1.tar.gz (188 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pybind11<2.6.2 (from nmslib)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\anzel\\appdata\\roaming\\python\\python313\\site-packages (from nmslib) (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in c:\\users\\anzel\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nmslib) (2.1.3)\n",
      "Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (pyproject.toml): started\n",
      "  Building wheel for nmslib (pyproject.toml): finished with status 'error'\n",
      "Failed to build nmslib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for nmslib (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [24 lines of output]\n",
      "      Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "      C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-taw9vr84\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-taw9vr84\\overlay\\Lib\\site-packages\\setuptools\\dist.py:488: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\\\\"2.1.1\\\\\"']\n",
      "      building 'nmslib' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for nmslib\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (nmslib)\n"
     ]
    }
   ],
   "source": [
    "!pip install nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Using cached lightfm-1.17.tar.gz (316 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [23 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "          ~~~~^^\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-gsrwxrg_\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-gsrwxrg_\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-gsrwxrg_\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "          ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\anzel\\AppData\\Local\\Temp\\pip-build-env-gsrwxrg_\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "          ~~~~^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 11, in <module>\n",
      "      AttributeError: 'dict' object has no attribute '__LIGHTFM_SETUP__' and no __dict__ for setting new attributes\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O3C_SMz6hiot"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightFM\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_at_k, recall_at_k\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "qfCOflZnhiou",
    "outputId": "aa55bacd-ccab-45c0-e483-ef59d2698d94"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/ratings.csv')\n",
    "books = pd.read_csv('data/books.csv')\n",
    "tags = pd.read_csv('data/tags.csv')\n",
    "book_tags = pd.read_csv('data/book_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u1TBykVuhiov"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "2        3              41865         41865  3212258          226  316015849   \n",
       "3        4               2657          2657  3275794          487   61120081   \n",
       "4        5               4671          4671   245494         1356  743273567   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "3  9.780061e+12                   Harper Lee                     1960.0   \n",
       "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WVIwztA5hiov"
   },
   "outputs": [],
   "source": [
    "mapper = dict(zip(books.goodreads_book_id,books.book_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxVDaPkKhiow"
   },
   "outputs": [],
   "source": [
    "tags = pd.read_csv('data/tags_cleaned.csv')\n",
    "book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]\n",
    "book_tags['id'] = book_tags.goodreads_book_id.apply(lambda x: mapper[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd_WvCLDhiow"
   },
   "outputs": [],
   "source": [
    "book_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3piw5iXUhiox"
   },
   "outputs": [],
   "source": [
    "ratings_coo = sparse.coo_matrix((ratings.rating,(ratings.user_id, ratings.book_id)))\n",
    "feature_ratings  = sparse.coo_matrix(([1]*len(book_tags), (book_tags.id, book_tags.tag_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp7ydLG-hiox"
   },
   "source": [
    "Объявим вспомогательные константы для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3bS12rOhioy"
   },
   "outputs": [],
   "source": [
    "#число потоков нашего процессора. Ставим 1, так как lightfm на macos ставится без OpenMP\n",
    "NUM_THREADS = 1\n",
    "\n",
    "#число параметров вектора \n",
    "NUM_COMPONENTS = 60\n",
    "\n",
    "#число эпох обучения\n",
    "NUM_EPOCHS = 10 \n",
    "\n",
    "#зерно датчика случайных чисел\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-1_C-UZhioy"
   },
   "source": [
    "На этапе создания модели мы используем библиотеку LightFM, чтобы сделать матричное разложение (ALS) наших рейтингов книг и получить два набора векторов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGxL87INhioz"
   },
   "outputs": [],
   "source": [
    "#Разбиваем наш датасет на обучающую и тестовую выборки\n",
    "train, test = random_train_test_split(ratings_coo, test_percentage=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "#Создаём модель\n",
    "model = LightFM(\n",
    "    learning_rate=0.05, #темп (скорость) обучения\n",
    "    loss='warp', #loss-функция\n",
    "    no_components=NUM_COMPONENTS,#размерность вектора признаков\n",
    "    random_state=RANDOM_STATE #генератор случайных чисел\n",
    ")\n",
    "\n",
    "#Обучаем модель\n",
    "model = model.fit(\n",
    "    train, #обучающая выборка\n",
    "    epochs=NUM_EPOCHS, #количество эпох обучения\n",
    "    num_threads=NUM_THREADS, #количество потоков процессора\n",
    "    item_features=feature_ratings #признаки товаров (рейтинги книг)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMupb7Schio0"
   },
   "source": [
    "Протестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6U1waVUshio0"
   },
   "outputs": [],
   "source": [
    "#Тестируем нашу модель\n",
    "precision_score = precision_at_k(\n",
    "    model, #модель\n",
    "    test, #тестовая выборка\n",
    "    num_threads=NUM_THREADS, #количество потоков процессора\n",
    "    k=10, #количество предложений\n",
    "    item_features=feature_ratings #признаки товаров\n",
    ").mean() #усредняем результаты\n",
    " \n",
    "recall_score = recall_at_k(\n",
    "    model, #модель\n",
    "    test, #тестовая выборка\n",
    "    num_threads=NUM_THREADS, #количество потоков процессора\n",
    "    k=10, #количество предложений\n",
    "    item_features=feature_ratings #признаки товаров\n",
    ").mean() #усредняем результаты\n",
    "\n",
    "print(recall_score, precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZUskAXXhio1"
   },
   "source": [
    "Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_uaCAe6hio1"
   },
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30o9Rtgyhio2"
   },
   "source": [
    "## Добавим эмбеддинги к модели и посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqsUKn57hio2"
   },
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQyl1ymbhio2"
   },
   "outputs": [],
   "source": [
    "# Достаём эбмеддинги\n",
    "item_biases, item_embeddings = model.get_item_representations(features=feature_ratings)\n",
    "\n",
    "print(item_biases.shape, item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bi1DHdBKhio3"
   },
   "outputs": [],
   "source": [
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NscQUR47hio3"
   },
   "outputs": [],
   "source": [
    "#Инициализируем наш граф для поиска\n",
    "nms_idx = nmslib.init(method='hnsw', space='cosinesimil')\n",
    " \n",
    "#Начинаем добавлять наши книги в граф\n",
    "nms_idx.addDataPointBatch(item_embeddings)\n",
    "nms_idx.createIndex(print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCtnO4s9hio3"
   },
   "outputs": [],
   "source": [
    "#Вспомогательная функция для поиска по графу\n",
    "def nearest_books_nms(book_id, index, n=10):\n",
    "    nn = index.knnQuery(item_embeddings[book_id], k=n)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PMM_uHfhio4"
   },
   "source": [
    "Найдем id книги 1984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Da3eHj7chio5"
   },
   "outputs": [],
   "source": [
    "#Отфильтруем только те, где в названии встречается подстрока \"1984\"\n",
    "books[books['title'].apply(lambda x: x.lower().find('1984')) >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hxEWTJghio5"
   },
   "source": [
    "Теперь найдем все похожие книги и посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вызываем функцию для поиска ближайших соседей\n",
    "print(nearest_books_nms(846, nms_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaVVOV9Whio6"
   },
   "outputs": [],
   "source": [
    "#Выделяем идентификаторы рекомендованных книг\n",
    "nbm = nearest_books_nms(846, nms_idx)[0]\n",
    "nbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTred3b8hio6"
   },
   "outputs": [],
   "source": [
    "#Посмотрим на авторов и названия рекомендованных книг\n",
    "books[books.book_id.isin(nbm)][['authors', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV45_3xhhio7"
   },
   "source": [
    "Сохраним эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUk-Xx4Zhio7"
   },
   "outputs": [],
   "source": [
    "with open('item_embeddings.pkl', 'wb') as file:\n",
    "    pickle.dump(item_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
>>>>>>> 4ab585d (change)
}
