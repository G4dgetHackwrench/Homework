{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import sleep, time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from selenium.webdriver.chrome.service import Service as EdgeService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"articles_info.csv\" # имя файла, в который будем сохранять результат\n",
    "executable_path = './msedgedriver.exe' # укажите ваш путь к chromedriver, который вы загрузили ранее\n",
    "base_dir= \"./data/\" # укажите директорию, в которую будем сохранять файл\n",
    "user_agent = \"Mozilla/5.0 ...\" # ваш user-agent, узнать его можно тут: https://юзерагент.рф, смотреть через браузер Chrome\n",
    "start_time = time() # время начала выполнения программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_time(article_url, user_agent):\n",
    "    #будем ждать 3 секунды, иначе выводить exception и присваивать константное значение\n",
    "    try:\n",
    "        # меняем значение заголовка. По умолчанию указано, что это python-код\n",
    "        headers = {\n",
    "            \"User-Agent\": user_agent\n",
    "        }\n",
    "        # делаем запрос по url статьи article_url\n",
    "        response = requests.get(\n",
    "            article_url, headers=headers, stream=True, timeout=3.000\n",
    "        )\n",
    "        # получаем время загрузки страницы\n",
    "        load_time = response.elapsed.total_seconds()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        load_time = \">3\"\n",
    "    return load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(output_list, filename, base_dir):\n",
    "    for row in output_list:\n",
    "        with open(Path(base_dir).joinpath(filename), \"a\") as csvfile:\n",
    "            fieldnames = [\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", \"comment\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_base(browser, page_number):\n",
    "    base_url = \"https://news.ycombinator.com/news?p={}\".format(page_number)\n",
    "    for connection_attempts in range(1,4): # совершаем 3 попытки подключения\n",
    "        try:\n",
    "            browser.get(base_url)\n",
    "            # ожидаем пока элемент table с id = 'hnmain' будет загружен на страницу\n",
    "            # затем функция вернет True иначе False \n",
    "            WebDriverWait(browser, 5).until(\n",
    "                EC.presence_of_element_located((By.ID, \"hnmain\"))\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error connecting to {}.\".format(base_url))\n",
    "            print(\"Attempt #{}.\".format(connection_attempts))\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html, user_agent):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    output_list = []\n",
    "   \n",
    "    # ищем в объекте soup object id, rank, score и title статьи\n",
    "    tr_blocks = soup.find_all(\"tr\", class_=\"athing\")\n",
    "    article = 0\n",
    "    for tr in tr_blocks:\n",
    "        article_id = tr.get(\"id\") # id\n",
    "        article_url = tr.find_all(\"a\")[1][\"href\"]\n",
    "\n",
    "        # иногда статья располагается не на внешнем сайте, а на ycombinator\n",
    "        # тогда article_url у нее не полный, а добавочный, с параметрами.\n",
    "        # например item?id=200933. Для этих случаев будем добавлять url до полного\n",
    "        if \"item?id=\" in article_url or \"from?site=\" in article_url:\n",
    "            article_url = f\"https://news.ycombinator.com/{article_url}\"\n",
    "        load_time = get_load_time(article_url, user_agent)\n",
    "        # иногда рейтинга может не быть, поэтому воспользуемся try\n",
    "\n",
    "        try:\n",
    "            score = soup.find(id=f\"score_{article_id}\").string\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            score = \"0 points\"\n",
    "            \n",
    "        try:\n",
    "            com = soup.find_all('a', href=f\"item?id={article_id}\")\n",
    "            com = com[1].string\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            com = \"0 comments\"\n",
    "           \n",
    "        article_info = {\n",
    "            \"id\": article_id,\n",
    "            \"load_time\": load_time,\n",
    "            \"rank\": tr.span.string,\n",
    "            \"points\": score,\n",
    "            \"title\": tr.find(class_=\"titleline\").string,\n",
    "            \"url\": article_url,\n",
    "            \"comment\": com\n",
    "        }\n",
    "\n",
    "        # добавляем информацию о статье в список\n",
    "        output_list.append(article_info)\n",
    "        article += 1\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time() # время начала выполнения программы\n",
    "\n",
    "# инициализируем веб драйвер\n",
    "#browser = webdriver.Edge(\n",
    "#    service=EdgeService(executable_path=executable_path)\n",
    "#)\n",
    "\n",
    "# перебираем страницы и собираем нужную информацию\n",
    "#for page_number in range(10):\n",
    "#    print(\"getting page \" + str(page_number) + \"...\")\n",
    "#    if connect_to_base(browser, page_number):\n",
    "#        sleep(5)\n",
    "#        output_list = parse_html(browser.page_source, user_agent)\n",
    "#        write_to_file(output_list, filename, base_dir)\n",
    "#\n",
    "#    else:\n",
    "#        print(\"Error connecting to hacker news\")\n",
    "\n",
    "# завершаем работу драйвера\n",
    "#browser.close()\n",
    "#sleep(1)\n",
    "#browser.quit()\n",
    "#end_time = time()\n",
    "#elapsed_time = end_time - start_time\n",
    "#print(\"run time: {} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'string'\n",
      "list index out of range\n",
      "HTTPSConnectionPool(host='www.euronews.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.linkedin.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.lemonde.fr', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='avi.im', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='newsroom.lexmark.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='talktomehuman.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.euronews.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='berthub.eu', port=443): Max retries exceeded with url: /articles/posts/on-long-term-software-development/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022DD7C41D60>, 'Connection to berthub.eu timed out. (connect timeout=3.0)'))\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='gizmodo.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='adam.math.hhu.de', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "'NoneType' object has no attribute 'string'\n",
      "list index out of range\n",
      "HTTPSConnectionPool(host='pubsonline.informs.org', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='engineering.fb.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.kannel.org', port=443): Max retries exceeded with url: /overview.shtml (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "HTTPSConnectionPool(host='engineering.fb.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='tracydurnell.com', port=443): Max retries exceeded with url: /2024/12/17/in-praise-of-the-hundred-page-idea/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022DD6BDB260>, 'Connection to tracydurnell.com timed out. (connect timeout=3.0)'))\n",
      "HTTPSConnectionPool(host='engineering.fb.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='agr.wa.gov', port=443): Max retries exceeded with url: /about-wsda/news-and-media-relations/news-releases?article=41658 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022DD6F72270>: Failed to resolve 'agr.wa.gov' ([Errno 11001] getaddrinfo failed)\"))\n",
      "HTTPSConnectionPool(host='abishekmuthian.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='netboxlabs.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.os2museum.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='robertvanwey.substack.com', port=443): Read timed out. (read timeout=3.0)\n",
      "Elapsed run time: 90.82737803459167 seconds\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "\n",
    "# Обернём процедуру парсинга страницы в функцию\n",
    "def run_process(page_number, filename):\n",
    "    browser = webdriver.Edge(\n",
    "        service=EdgeService(executable_path=executable_path)\n",
    "    )\n",
    "    if connect_to_base(browser, page_number):\n",
    "        sleep(5)\n",
    "        output_list = parse_html(browser.page_source, user_agent)\n",
    "        #write_to_file(output_list, filename, base_dir)\n",
    "        save_to_db(output_list)\n",
    "        browser.quit()\n",
    "    else:\n",
    "        print(\"Error connecting to hacker news\")\n",
    "        browser.quit()\n",
    "       \n",
    "# Глобальные переменные        \n",
    "filename = \"articles_info_new.csv\" # имя файла, в который будем сохранять результат\n",
    "executable_path = './msedgedriver.exe' # укажите ваш путь к chromedriver, который вы загрузили ранее\n",
    "base_dir= \"./data/\" # укажите директорию, в которую будем сохранять файл\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "\n",
    "# Засечём время выполнения кода\n",
    "start_time = time()\n",
    "\n",
    "futures = []\n",
    "\n",
    "# Запустим процесс парсинга на нескольких потоках одновременно\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for number in range(10):\n",
    "        futures.append(\n",
    "            executor.submit(run_process, number, filename)\n",
    "        )\n",
    "       \n",
    "wait(futures)\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed run time: {} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_data_new = pd.read_csv(\n",
    "    './data/articles_info_new.csv',\n",
    "    names=[\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", \"comment\"],\n",
    "    encoding='cp1252'\n",
    ")\n",
    "\n",
    "articles_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>load_time</th>\n",
       "      <th>rank</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42443456</td>\n",
       "      <td>0.674293</td>\n",
       "      <td>151.0</td>\n",
       "      <td>27 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.natesilver.net/p/save-daylight-sav...</td>\n",
       "      <td>54 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42457383</td>\n",
       "      <td>0.26473</td>\n",
       "      <td>152.0</td>\n",
       "      <td>41 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pmc.ncbi.nlm.nih.gov/articles/PMC3536509/</td>\n",
       "      <td>17 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42487746</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>153.0</td>\n",
       "      <td>53 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theatlantic.com/ideas/archive/2024...</td>\n",
       "      <td>86 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42454359</td>\n",
       "      <td>0.535328</td>\n",
       "      <td>154.0</td>\n",
       "      <td>679 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/pwr-Solaar/Solaar</td>\n",
       "      <td>259 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42437201</td>\n",
       "      <td>0.862806</td>\n",
       "      <td>155.0</td>\n",
       "      <td>170 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arstechnica.com/health/2024/12/huge-ma...</td>\n",
       "      <td>111 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>42461539</td>\n",
       "      <td>0.548806</td>\n",
       "      <td>56.0</td>\n",
       "      <td>24 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://netboxlabs.com/blog/netbox-discovery-a...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>42456802</td>\n",
       "      <td>0.27983</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://genesis-embodied-ai.github.io/</td>\n",
       "      <td>2 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>42479661</td>\n",
       "      <td>0.088637</td>\n",
       "      <td>58.0</td>\n",
       "      <td>21 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.chicagotribune.com/2024/12/21/chic...</td>\n",
       "      <td>2 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>42492949</td>\n",
       "      <td>0.670603</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://finance.yahoo.com/news/france-links-fi...</td>\n",
       "      <td>2 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>42473321</td>\n",
       "      <td>0.243328</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1674 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arcprize.org/blog/oai-o3-pub-breakthrough</td>\n",
       "      <td>1711 comments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id load_time   rank       points title  \\\n",
       "0    42443456  0.674293  151.0    27 points   NaN   \n",
       "1    42457383   0.26473  152.0    41 points   NaN   \n",
       "2    42487746  0.932203  153.0    53 points   NaN   \n",
       "3    42454359  0.535328  154.0   679 points   NaN   \n",
       "4    42437201  0.862806  155.0   170 points   NaN   \n",
       "..        ...       ...    ...          ...   ...   \n",
       "295  42461539  0.548806   56.0    24 points   NaN   \n",
       "296  42456802   0.27983   57.0    80 points   NaN   \n",
       "297  42479661  0.088637   58.0    21 points   NaN   \n",
       "298  42492949  0.670603   59.0    22 points   NaN   \n",
       "299  42473321  0.243328   60.0  1674 points   NaN   \n",
       "\n",
       "                                                   url        comment  \n",
       "0    https://www.natesilver.net/p/save-daylight-sav...    54 comments  \n",
       "1    https://pmc.ncbi.nlm.nih.gov/articles/PMC3536509/    17 comments  \n",
       "2    https://www.theatlantic.com/ideas/archive/2024...    86 comments  \n",
       "3                 https://github.com/pwr-Solaar/Solaar   259 comments  \n",
       "4    https://arstechnica.com/health/2024/12/huge-ma...   111 comments  \n",
       "..                                                 ...            ...  \n",
       "295  https://netboxlabs.com/blog/netbox-discovery-a...        discuss  \n",
       "296             https://genesis-embodied-ai.github.io/     2 comments  \n",
       "297  https://www.chicagotribune.com/2024/12/21/chic...     2 comments  \n",
       "298  https://finance.yahoo.com/news/france-links-fi...     2 comments  \n",
       "299  https://arcprize.org/blog/oai-o3-pub-breakthrough  1711 comments  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "connection = psycopg2.connect(user='postgres',\n",
    "                                  password=123580,\n",
    "                                  host='localhost',\n",
    "                                  port=5432,\n",
    "                                  database=\"test_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.autocommit = True\n",
    "\n",
    "\n",
    "# запись в бд происходит с помощью “курсора”. Мы пишем запрос и выполняем его с помощью execute\n",
    "with connection.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS articles;\n",
    "    CREATE TABLE articles(\n",
    "    id integer,\n",
    "    load_time text,\n",
    "    rank text,\n",
    "    points text,\n",
    "    title text,\n",
    "    url text\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_db(output_list):\n",
    "    with connection.cursor() as cursor:\n",
    "\t\t#пробегаемся по строкам с результатом и вставляем значения в строку. Для вставки данных в таблицу используем конструкцию INSERT INTO TABLE\n",
    "        for row in output_list:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO articles VALUES (\n",
    "                '{}',\n",
    "                '{}', \n",
    "                '{}',\n",
    "                '{}', \n",
    "                '{}', \n",
    "                '{}'\n",
    "                );\n",
    "            \"\"\".format(row['id'],row['load_time'],row['rank'], row['points'], row['title'], row['url'], row['comment']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
